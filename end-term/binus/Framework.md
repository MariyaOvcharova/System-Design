# Выбор стримингового фреймворка в 2024 году #

Ссылка на видео: https://www.youtube.com/watch?v=tbv4lyIkBl0
Ссылка на презентацию: https://disk.yandex.ru/i/wgCg5SonQBPwyQ

Выбор стримингового фреймворка - это не просто выбрать по списку кто быстрее, моднее и популярнее на рынке,
надо реально понимать под какую задачу ты берешь фреймворк
и почти всегда всё упирается не в красивые фичи, а в реальные требования бизнеса
и в то насколько быстро и надёжно можно запустить джобы в продакшн

Максим Буйлин (тот кто защищал презентацию) рассказывает как выбрать стриминговый фреймворк в реальной жизни на примерах
Он делится опытом запуска стриминговой платформы Unicorn
и приводит кейс запуска маркетинговой акции где нужно было обрабатывать потоки почти в реальном времени

## Что за задача была ##

есть два потока событий в Kafka
- надо объединить их
- сделать агрегации
- отдать результат снова в Kafka

время между транзакцией и продажей должно быть не больше 30 секунд и всё это должно работать на проде через неделю
Задача с жёсткими сроками и требованиями

* Критерии выбора фреймворка * 
- умение объединять потоки (реальные join а не просто enrichment из кэша)
- простота запуска в распределенной среде (типа Kubernetes)
- активное развитие комьюнити (чтоб фиксы и новые фичи выходили)
- масштабируемость под пиковые нагрузки

Что рассматривали
Apache Nifi - не подходит для join'ов потоков
Apache Beam - тоже отпал потому что по сути всё равно Spark или Flink
Storm и Samza - старые, новых фич мало, для новых проектов не советует

Остались в основном два кандидата - * Apache Spark * и * Apache Flink *

### Про Apache Spark ###
- умеет работать через микробатчи (micro-batch), то есть обрабатывает пачку событий за раз
- у Spark крутое сообщество, много фич, в основном для пакетной обработки но стриминг тоже развивается
- Spark хорошо запускается в Kubernetes
но continuous streaming до сих пор в эксперименте

Dynamic Allocation (авто-масштабирование ресурсов) в стриминге работает криво, можно потерять микробатчи

### Про Apache Flink ###
- Flink обрабатывает события по одному (element-at-a-time)это даёт минимальные задержки
- Flink тоже умеет масштабироваться через Reactive Mode
- сообщество активно развивает Flink
- быстрые релизы, но иногда попадаются баги из-за скорости развития
- Flink требует аккуратного управления ресурсами но в плане стриминга выглядит более зрелым чем Spark

Опыт спикера
В 2019 году они выбрали Spark потому что:
- была уже экспертиза в Spark
- Flink тогда был сыроват
- задача позволяла мириться с микробатчами

Прошло 5 лет - и сейчас видно что Spark сильно развился но continuous streaming всё ещё не production-ready
а Flink наоборот сильно прокачался в стриминге

### Плюсы и минусы подходов ###
- Spark проще поддерживать если у тебя уже всё на Spark
- Flink лучше если тебе важна минимальная задержка и высокая точность стриминга
- Spark иногда проще развернуть быстро в прод
- Flink требует больше подготовки но даёт лучше latency

## Про масштабирование под нагрузку ##
В Spark dynamic allocation плохо работает для стриминга приходится останавливать и перезапускать job чтобы поменять ресурсы можно добавить shutdown hook чтобы сохранить текущий микробатч перед остановкой

В Flink масштабирование сделано лучше за счёт reactive mode - новые task менеджеры подхватываются автоматически

Выводы Максима
если задача простая и есть экспертиза в Spark - можно оставаться на нём, если нужно делать real-time с минимальной задержкой и готовы вложиться - лучше брать Flink. Библиотеки типа Kafka Streams хороши если строишь небольшое встроенное решение а не полноценную платформу. Старые фреймворки типа Storm или Samza - оставлять только если уже есть в проде, для новых проектов * не брать. *

Ещё важный момент - фреймворк надо выбирать не по моде а по задачам бизнеса
это часто забывают когда просто смотрят на хайп вокруг технологий

### Вывод ###
Выбор стримингового фреймворка - это не гонка за модой

Это трезвая оценка:
- какие задачи надо решить
- какие задержки допустимы
- сколько ресурсов и экспертизы есть

Если подойти к этому с головой, можно сильно сэкономить силы и деньги
а если слепо гнаться за трендами - можно угробить проект

