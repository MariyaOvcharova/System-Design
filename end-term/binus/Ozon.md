# Обновления данных в поиске за секунды. Петр Портнов #
Ссылка на видео: https://www.youtube.com/watch?v=3vRkFNgjCwU 
Ссылка на презентацию: https://disk.yandex.ru/i/o07YdnfrdT9scA

В видео рассказывается как команда Озона решила проблему медленного обновления данных в поиске. Бизнесу нужно было чтобы цены и наличие на товары менялись почти мгновенно, а старый способ работы был слишком медленным. Пришлось полностью переосмыслить как хранить и обновлять данные, чтобы всё работало быстро и надёжно.

## О чём рассказ ##
Поиск в Озоне устроен на базе Lucene, это движок для индексации текстов. В нём есть прямой и обратный индекс. Прямой индекс хорошо подходит для фильтрации товаров, но плохо справляется с частыми обновлениями данных. Раньше если надо было поменять цену или остаток товара, приходилось пересоздавать весь документ целиком. Это занимало много времени и сильно тормозило работу поиска.

Когда бизнес стал требовать почти мгновенные обновления, команда поняла что старый способ не подходит. Попробовали использовать готовые базы данных типа RocksDB и LMDB, но оказалось что они не дают нужной скорости при их объёмах данных. Поэтому было решено сделать своё решение — быстрые поля, которые можно обновлять отдельно и без пересоздания всего документа.

Основная идея была в том, чтобы отделить часто меняющиеся поля от основного индекса и обновлять их в отдельном хранилище. Но это привело к новым проблемам. Например, надо было чтобы поиск оставался быстрым, даже если данные берутся из двух мест. Ещё были большие сложности с памятью, потому что объёмы данных особенно по складам были очень большими.

Команда придумала несколько оптимизаций. Они заметили что ключи почти всегда целые числа и сделали хранение данных максимально простым. Также добавили дедупликацию одинаковых данных и сжатие, чтобы экономить место. Были сделаны механизмы быстрого восстановления после перезапусков, чтобы не терять актуальные данные.

Всё это дало результат - обновления цен и остатков теперь проходят за 1-2 секунды, а скорость поиска осталась на высоком уровне.

Они не стали просто брать готовую базу данных которая не подходила под их задачи, а пошли сложным путём и сделали всё сами. Это требует глубокого понимания как работает их система и какие именно требования стоят перед ними.Иногда лучше написать своё решение чем пытаться приспособить чужое, особенно если на кону стоит скорость работы и стабильность. Они сразу подумали про такие вещи как восстановление после сбоев и параллельная работа, потому что в реальных системах это часто забывают и потом возникают большие проблемы.

Единственное что мне показалось немного сложным - это часть про дедупликацию данных через хеш-таблицы. Не до конца поняла все детали как это устроено, но в целом идея - максимально экономить память и ускорять доступ к данным.

## Вывод ##
Результат показал что быстрое обновление данных в большом поисковом движке - не простая задача. Пришлось продумывать архитектуру с нуля, учитывать особенности работы индекса, оптимизировать память и доступ к данным. Озон справились с этим хорошо, показали что иногда лучше сделать своё решение чем пытаться использовать чужое. Это показывает как важно думать про реальные требования бизнеса и особенности системы, а не просто использовать модные технологии. Также стало понятно что настоящая оптимизация это всегда про кучу мелких деталей, без которых ничего быстро работать не будет.
