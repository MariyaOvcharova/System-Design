# YTsaurus SPYT: внедряем Spark SQL в массы #
Ссылка на видео: https://www.youtube.com/watch?v=b8rs9_r498k
ССылка на презентацию: https://disk.yandex.ru/i/zqreBMwLcAR4gw

## Основная мысль ##
Доклад был про то, как команда из Яндекса пыталась упростить работу с Spark SQL для пользователей. И что подключить Spark к их платформе оказалось намного сложнее, чем казалось.

Почему вообще Spark SQL
- Spark мощный инструмент для работы с большими данными.
Но чтобы им пользоваться, нужно ставить клиента, настраивать подключения, сессии, тратить время.
-Хотелось, чтобы пользователь мог просто написать SQL запрос через веб и не думать о сложной настройке.
-Многие пользователи уже имели свои Spark-кластера, и можно было использовать их мощности.

### Тезисы ###
Подключить Spark оказалось не так просто
Хотя изначально всё выглядело легко, в реальности оказалось, что надо:

- запускать запросы на кластере
- получать результаты обратно
- уметь отменять выполнение, если пользователь передумал

## Из коробки поддерживался только SELECT ##
Сначала через систему можно было выполнять только SELECT запросы.
То есть пользователь мог только читать данные, а изменять их (INSERT, UPDATE, DELETE) — нельзя.
Потом команда доработала систему:
Добавили поддержку создания таблиц (CREATE TABLE) и вставки данных (INSERT).
Но полноценная поддержка UPDATE и DELETE всё ещё остаётся сложной из-за особенностей работы Spark.

## Использование Livy ##
Нашли Livy - сервер, который позволяет через HTTP отправлять команды в Spark.
Суть:
- создать сессию
- отправить SQL запрос
- получить ответ

Но Livy принимает только код на Scala. Поэтому придумали способ:

обернуть результат запроса в бинарный формат, закодировать его в base64, потом уже пересылать и распаковывать обратно.

* Ускорение работы запросов *
Поначалу выполнение простого запроса занимало 25 секунд.

Чтобы ускорить работу:
- стали переиспользовать уже открытые сессии для одного пользователя
- дописали маленький патч в Livy, чтобы искать и повторно использовать сессии

* Это помогло сократить время выполнения до 2-5 секунд на повторных запросах. *

## Улучшение интерфейса для пользователей ##
-Добавили выбор кластера из всплывающего окошка
-Сделали отображение прогресса выполнения запроса (сколько процентов сделано)
-Нарисовали графы исполнения запросов в интерфейсе.

Теперь пользователь видит наглядно, что происходит с его запросом.

## Проще запускать кластера ##
* Раньше пользователь сам должен был запускать кластер через клиента *

Теперь:
пользователь делает запись, что ему нужен кластер, система сама поднимает нужные машины, всё это происходит автоматически, без лишней боли.

## Работа с таблицами и данными ##
Постоянные таблицы (CREATE TABLE) сохраняются навсегда.

Временные представления (VIEW) пока живут только внутри одной сессии и исчезают после её завершения.

### Итог ###
Команда сделала так, что:
любой пользователь мог писать SQL запросы без сложной настройки,запросы работали быстрее, особенно после первых запусков, интерфейс стал понятнее, с отображением прогресса и графов выполнения, поднимать и управлять кластерами стало легче.

Переход был сложным, пришлось делать патчи, дописывать код, решать кучу мелких проблем.
Но теперь система реально помогает работать с большими данными через Spark гораздо проще и удобнее.
